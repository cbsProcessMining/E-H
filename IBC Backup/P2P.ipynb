{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname, abspath\n",
    "#_PARENT_DIR = dirname(dirname(dirname(abspath(__file__))))\n",
    "#sys.path.append(_PARENT_DIR)\n",
    "#from utils._utils import parse_celonis_url, get_user_data, get_logger              ### <--\n",
    "from pycelonis import get_celonis\n",
    "import argparse\n",
    "#logger = get_logger()\n",
    "def unify_tables(url, api_token, datapool, tables, tableSchema, function = 'null'):\n",
    "    \n",
    "    #loop through defined tables\n",
    "    #for table_name in tables:\n",
    "       \n",
    "    c = get_celonis(url, api_token)\n",
    "    #get_user_data(c, 'Table Unifier')\n",
    "    #url_options= parse_celonis_url(url)                                            ### <--\n",
    "    #pool = c.pools.find(url_options['id'])                                         ### <--\n",
    "    \n",
    "    pool = c.pools.find(datapool)                                                   ### <--\n",
    "\n",
    "    minReq = []\n",
    "    maxReq = []\n",
    "    sameTables = []\n",
    "    schemalist = tableSchema                                                        # added to extract required table schemas (in python list format)\n",
    "    columns = ''\n",
    "    select = ''\n",
    "    \n",
    "    # create or find global data job \n",
    "    try:\n",
    "        global_dj = pool.data_jobs.find('Unify Tables')\n",
    "    except:\n",
    "        global_dj = pool.create_data_job(name = 'Unify Tables')\n",
    "    \n",
    "    #loop through defined tables\n",
    "    for table_name in tables:\n",
    "    \n",
    "        # find tables to unify\n",
    "        x = 0\n",
    "        for schema in global_dj.tables:\n",
    "            for table in schema:\n",
    "                x = x + 1\n",
    "                if table['schemaName'] not in schemalist:\n",
    "                    continue\n",
    "                if table['name'] == table_name:\n",
    "                    sameTables.append(table)\n",
    "        \n",
    "        if len(sameTables) == 0:\n",
    "            print('TABLE', table_name, 'CAN NOT BE UNIFIED! Not existing in source systems!')\n",
    "            global_dj.create_transformation(name = \"Unify \" + table_name, statement = '-- no existing tables to unify in defined source systems')\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # create minimal column requirement\n",
    "            for col in sameTables[0]['columns']:\n",
    "                try:\n",
    "                    if col in sameTables[1]['columns']:                                              # ERROR CHECKING !\n",
    "                        minReq.append(col)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            \"\"\"\n",
    "            #only required if function = 'min'\n",
    "\n",
    "            if len(sameTables) > 2:\n",
    "                for table in sameTables[2:]:\n",
    "                    for col in minReq:\n",
    "                        if col not in table['columns']:\n",
    "                            minReq.pop(col)\n",
    "                # create transformation statement for minimal table requirement\n",
    "\n",
    "            if function == 'min':\n",
    "                for col in minReq:\n",
    "                    if(minReq.index(col) == 0):\n",
    "                        columns += '{}\\n'.format(col['name'])\n",
    "                    else:\n",
    "                        columns += ',{}\\n'.format(col['name'])\n",
    "                for table in sameTables:\n",
    "                    select += 'SELECT \\n{}FROM \"{}\".\"{}\"'.format(columns, table['schemaName'], table_name)\n",
    "                    if table != sameTables[len(sameTables)-1]:\n",
    "                        select += '\\nUNION ALL\\n'\n",
    "            \"\"\"            \n",
    "\n",
    "            # create transformation for statement for extension with null\n",
    "            if function == 'null':\n",
    "                #columns = ''\n",
    "                #select = ''\n",
    "                \n",
    "                for table in sameTables:\n",
    "                    for col in table['columns']:\n",
    "                        if col not in maxReq:\n",
    "                            maxReq.append(col)\n",
    "                for table in sameTables:\n",
    "                    for col in maxReq:\n",
    "                        if(maxReq.index(col) == 0):\n",
    "                            columns += \"'\" + table['schemaName'] + \"' \" + 'AS \"SCHEMA\"\\n' + ',{}\\n'.format('\"' + col['name'] + '\"' if col in table['columns'] else 'NULL AS \"' + col['name'] + '\"')\n",
    "                        else:\n",
    "                            columns += ',{}\\n'.format('\"' + col['name'] + '\"' if col in table['columns'] else 'NULL AS \"' + col['name'] + '\"')\n",
    "                    select += 'SELECT \\n{}FROM \"{}\".\"{}\"'.format(columns, table['schemaName'], table_name)\n",
    "                    columns = ''\n",
    "                    if table != sameTables[len(sameTables)-1]:\n",
    "                        select += '\\nUNION ALL\\n'\n",
    "            # create transformation\n",
    "            #statement = 'DROP VIEW IF EXISTS \"{}_UNIFIED\";\\n\\nCreate VIEW \"{}_UNIFIED\" AS(\\n{}\\n);'.format(table_name, table_name, select)\n",
    "            statement = 'DROP VIEW IF EXISTS \"{}\";\\n\\nCreate VIEW \"{}\" AS(\\n{}\\n);'.format(table_name, table_name, select)                      ### <-- Unified\n",
    "            global_dj.create_transformation(name = \"Unify \" + table_name, statement = statement)\n",
    "            print('The union statement has been saved in the global data job \"Unify Tables\" for Table', table_name)\n",
    "            select = ''\n",
    "            sameTables = []\n",
    "            minReq = []\n",
    "            maxReq = []\n",
    "            \n",
    "            # reminder: datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://endresshauser.eu-3.celonis.cloud/'\n",
    "\n",
    "# Specify a valid API token for your Cloud Team.\n",
    "#Click on Team Settings -> Edit -> create or copy already inserted API key\n",
    "\n",
    "api_token = 'NDEzZDFkN2YtZjVmZC00MTE0LTg2ODAtNmZlZDM5YzU5YTEwOjBxR0xOSFhjdDQ4MFNDc0V1UDIwbldzNWd2VXFVeUZieCt5MjdzbUhySkRP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10 14:27:55 - pycelonis: Login successful! The Application Key currently has access to 0 Analyses and to 4 Data Pools.\n"
     ]
    }
   ],
   "source": [
    "celonis = get_celonis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10 14:27:58 - pycelonis: Login successful! The Application Key currently has access to 0 Analyses and to 4 Data Pools.\n"
     ]
    }
   ],
   "source": [
    "  c = get_celonis(url, api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Pool, id e1bd9ca9-9d3b-44b4-9c17-ae345f663e27, name SAP ECC - Purchase to Pay>,\n",
       "<Pool, id 590652c7-87a4-46e6-a9e9-60c90cb7c4e3, name SAP ECC - Production Planning>,\n",
       "<Pool, id 98d9fc62-ccbf-4158-b89f-cb8a7a976a2d, name SAP ECC - Warehouse Management>,\n",
       "<Pool, id 60442433-3dbb-4ce6-8ed3-e9bb7238c614, name SAP ECC - Order to Cash>,]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celonis.pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapool = 'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27'\n",
    "\n",
    "pool = celonis.pools.find(datapool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DataConnection, id 77f18ab5-b465-4e03-8f67-0272cd01ddfb, name SAP ECC - PIN-020>,\n",
       "<DataConnection, id 310d0ab5-5bb5-4d64-8a34-84bc93121d58, name SAP ECC - PIN-024>,\n",
       "<DataConnection, id 8adecd8c-3535-43d2-bb7c-af12f175e8f5, name SAP ECC - PS1-033>,\n",
       "<DataConnection, id a61e719d-5566-4328-b183-1d393f8879aa, name SAP ECC - PS1-035>,\n",
       "<DataConnection, id b6fbc486-9719-4d69-87dc-50a471c5f95f, name SAP ECC - PS1-036>,\n",
       "<DataConnection, id def198a6-426d-4ccb-b0ec-52dc2d1c519a, name SAP ECC - PS1-038>,\n",
       "<DataConnection, id 98f12823-2c82-4df3-a4e0-3f932fb27879, name SAP ECC - PS1-039>,\n",
       "<DataConnection, id d04e6dc0-5b53-420a-b624-8eed5d1b7db7, name SAP ECC - PS1-030>,\n",
       "<DataConnection, id 621b2b5e-1c46-4e81-b13b-15bc607ff983, name SAP ECC - PS1-007>,\n",
       "<DataConnection, id ffdff050-1fe4-43aa-ae9a-cd4763450e59, name SAP ECC - PS1-040>,\n",
       "<DataConnection, id 5a2082de-1aec-4bff-850c-7a923f2d094b, name SAP ECC - PS1-044>,\n",
       "<DataConnection, id 70f5784d-f0b6-4ce0-a368-6104c27a245b, name SAP ECC - PS1-032>,\n",
       "<DataConnection, id 7982c009-f641-4fa7-b74c-4c79febc733a, name SAP ECC - PSG-045>,\n",
       "<DataConnection, id 00409fbb-dad1-444e-90c1-c026cf6b9588, name SAP ECC - PSG-048>,\n",
       "<DataConnection, id b9ddf35b-8fa1-4f45-a41d-c873e600ca7c, name SAP ECC - PS1-090>,\n",
       "<DataConnection, id 90db209c-f801-4c03-90d2-dac4c191ba9b, name SAP ECC - PSG-049>,\n",
       "<DataConnection, id 7a3bafc7-ae0a-4c96-82bf-0e16ba8ff97d, name SAP ECC - PCA-042>,\n",
       "<DataConnection, id 9363d8e4-bbd1-4454-ab9f-b115ab31aa5c, name SAP ECC - PP1-011>,\n",
       "<DataConnection, id 1c0a359a-f05b-4fa7-8cac-b0018a68ee74, name SAP ECC - PP2-004>,\n",
       "<DataConnection, id 920b7d87-7487-47b2-b46a-0727145161ce, name SAP ECC - PP2-005>,]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.data_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-15 15:15:01 - pycelonis: Login successful! Hello josef.rieger@cbs-consulting.de\n",
      "2020-10-15 15:15:02 - pycelonis: Best matches: [(0.44, 'PSG 049 - SAP P2P Extractions Full Load'), (0.44, 'PSG 048 - SAP P2P Extractions Full Load'), (0.44, 'PSG 045 - SAP P2P Extractions Full Load')]\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table BKPF\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table BSEG\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table CDHDR\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table CDPOS\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table DD02T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table DD03M\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table DD07T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EBAN\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EINA\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EKBE\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EKES\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EKET\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EKKO\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table EKPO\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LFA1\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LFB1\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LFM1\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LIKP\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LTAK\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LTAP\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MAKT\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MARA\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MARC\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MKPF\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MSEG\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table NAST\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table QALS\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table QAVE\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table QPAM\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table QPCD\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table QPGR\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table RBKP\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table RSEG\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T001\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T001L\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T001W\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T008T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T023T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T024\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T024E\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T161T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T163I\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T163Y\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T16FE\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T179T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T685T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURF\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURR\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURV\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURX\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table USR02\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table VBFA\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table ZZFAX01\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T320\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T134T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T307T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T077Y\n"
     ]
    }
   ],
   "source": [
    "# URL to the Cloud Data Pool where the tables to unify are hosted.\n",
    "url = 'https://endresshauser.eu-3.celonis.cloud/'\n",
    "\n",
    "# Specify a valid API token for your Cloud Team.\n",
    "#Click on Team Settings -> Edit -> create or copy already inserted API key\n",
    "\n",
    "api_token = 'NDEzZDFkN2YtZjVmZC00MTE0LTg2ODAtNmZlZDM5YzU5YTEwOjBxR0xOSFhjdDQ4MFNDc0V1UDIwbldzNWd2VXFVeUZieCt5MjdzbUhySkRP'\n",
    "\n",
    "\n",
    "#To get the data pool id, you have to run the following code. To get the data\n",
    "#the ML User here called Global needs permission to request these informations\n",
    "#celonis = get_celonis()\n",
    "#celonis.pools by that you get the ID for the data pool \n",
    "\n",
    "# Specify a datapool -- P2P Data Pool ID\n",
    "datapool = 'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27'\n",
    "\n",
    "# Specify the table names for which the tables should be merged. \n",
    "\n",
    "tables = ['BKPF','BSEG','CDHDR','CDPOS','DD02T','DD03M','DD07T','EBAN','EINA','EKBE','EKES','EKET','EKKO','EKPO','LFA1','LFB1','LFM1','LIKP','LTAK','LTAP','MAKT','MARA','MARC','MKPF','MSEG','NAST','QALS','QAVE','QPAM','QPCD','QPGR','RBKP','RSEG','T001','T001L','T001W','T008T','T023T','T024','T024E','T161T','T163I','T163Y','T16FE','T179T','T685T','TCURF','TCURR','TCURV','TCURX','USR02','VBFA','ZZFAX01', 'T320','T134T','T307T','T077Y']\n",
    "\n",
    "# Specify 'min' if the unified table should be the minimal column requirement and 'null' if the not existing columns should be filled with null values.\n",
    "function = 'null'\n",
    "\n",
    "#Schema Information\n",
    "\n",
    "#<DataConnection, id 77f18ab5-b465-4e03-8f67-0272cd01ddfb, name SAP ECC - PIN-020>,\n",
    "#<DataConnection, id 310d0ab5-5bb5-4d64-8a34-84bc93121d58, name SAP ECC - PIN-024>,\n",
    "#<DataConnection, id 8adecd8c-3535-43d2-bb7c-af12f175e8f5, name SAP ECC - PS1-033>,\n",
    "#<DataConnection, id a61e719d-5566-4328-b183-1d393f8879aa, name SAP ECC - PS1-035>,\n",
    "#<DataConnection, id b6fbc486-9719-4d69-87dc-50a471c5f95f, name SAP ECC - PS1-036>,\n",
    "#<DataConnection, id def198a6-426d-4ccb-b0ec-52dc2d1c519a, name SAP ECC - PS1-038>,\n",
    "#<DataConnection, id 98f12823-2c82-4df3-a4e0-3f932fb27879, name SAP ECC - PS1-039>,\n",
    "#<DataConnection, id d04e6dc0-5b53-420a-b624-8eed5d1b7db7, name SAP ECC - PS1-030>,\n",
    "#<DataConnection, id 621b2b5e-1c46-4e81-b13b-15bc607ff983, name SAP ECC - PS1-007>,\n",
    "#<DataConnection, id ffdff050-1fe4-43aa-ae9a-cd4763450e59, name SAP ECC - PS1-040>,\n",
    "#<DataConnection, id 5a2082de-1aec-4bff-850c-7a923f2d094b, name SAP ECC - PS1-044>,\n",
    "#<DataConnection, id 70f5784d-f0b6-4ce0-a368-6104c27a245b, name SAP ECC - PS1-032>,\n",
    "#<DataConnection, id 7982c009-f641-4fa7-b74c-4c79febc733a, name SAP ECC - PSG-045>,\n",
    "#<DataConnection, id 00409fbb-dad1-444e-90c1-c026cf6b9588, name SAP ECC - PSG-048>,\n",
    "#<DataConnection, id 90db209c-f801-4c03-90d2-dac4c191ba9b, name SAP ECC - PSG-049>,\n",
    "#<DataConnection, id 7a3bafc7-ae0a-4c96-82bf-0e16ba8ff97d, name SAP ECC - PCA-042>,\n",
    "#<DataConnection, id 9363d8e4-bbd1-4454-ab9f-b115ab31aa5c, name SAP ECC - PP1-011>,\n",
    "#<DataConnection, id 1c0a359a-f05b-4fa7-8cac-b0018a68ee74, name SAP ECC - PP2-004>,\n",
    "#<DataConnection, id 920b7d87-7487-47b2-b46a-0727145161ce, name SAP ECC - PP2-005>,\n",
    "#<DataConnection, id b9ddf35b-8fa1-4f45-a41d-c873e600ca7c, name SAP ECC - PS1-090>\n",
    "\n",
    "\n",
    "\n",
    "# Specify the required table schemas in a python list\n",
    "#To acess the Schema Name you have to get the connection informations\n",
    "#pool.data_connections\n",
    "tableSchema = [\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_9363d8e4-bbd1-4454-ab9f-b115ab31aa5c',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_77f18ab5-b465-4e03-8f67-0272cd01ddfb',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_310d0ab5-5bb5-4d64-8a34-84bc93121d58',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_8adecd8c-3535-43d2-bb7c-af12f175e8f5',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_a61e719d-5566-4328-b183-1d393f8879aa',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_b6fbc486-9719-4d69-87dc-50a471c5f95f',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_def198a6-426d-4ccb-b0ec-52dc2d1c519a',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_98f12823-2c82-4df3-a4e0-3f932fb27879',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_d04e6dc0-5b53-420a-b624-8eed5d1b7db7',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_621b2b5e-1c46-4e81-b13b-15bc607ff983',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_ffdff050-1fe4-43aa-ae9a-cd4763450e59',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_5a2082de-1aec-4bff-850c-7a923f2d094b',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_70f5784d-f0b6-4ce0-a368-6104c27a245b',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_7982c009-f641-4fa7-b74c-4c79febc733a',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_00409fbb-dad1-444e-90c1-c026cf6b9588',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_90db209c-f801-4c03-90d2-dac4c191ba9b',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_7a3bafc7-ae0a-4c96-82bf-0e16ba8ff97d',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_1c0a359a-f05b-4fa7-8cac-b0018a68ee74',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_920b7d87-7487-47b2-b46a-0727145161ce',\n",
    "'e1bd9ca9-9d3b-44b4-9c17-ae345f663e27_b9ddf35b-8fa1-4f45-a41d-c873e600ca7c'    \n",
    "]\n",
    "\n",
    "unify_tables(url = url, api_token = api_token, datapool = datapool, tables = tables, tableSchema = tableSchema, function = function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
