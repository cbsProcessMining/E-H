{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname, abspath\n",
    "#_PARENT_DIR = dirname(dirname(dirname(abspath(__file__))))\n",
    "#sys.path.append(_PARENT_DIR)\n",
    "#from utils._utils import parse_celonis_url, get_user_data, get_logger              ### <--\n",
    "from pycelonis import get_celonis\n",
    "import argparse\n",
    "#logger = get_logger()\n",
    "def unify_tables(url, api_token, datapool, tables, tableSchema, function = 'null'):\n",
    "    \n",
    "    #loop through defined tables\n",
    "    #for table_name in tables:\n",
    "       \n",
    "    c = get_celonis(url, api_token)\n",
    "    #get_user_data(c, 'Table Unifier')\n",
    "    #url_options= parse_celonis_url(url)                                            ### <--\n",
    "    #pool = c.pools.find(url_options['id'])                                         ### <--\n",
    "    \n",
    "    pool = c.pools.find(datapool)                                                   ### <--\n",
    "\n",
    "    minReq = []\n",
    "    maxReq = []\n",
    "    sameTables = []\n",
    "    schemalist = tableSchema                                                        # added to extract required table schemas (in python list format)\n",
    "    columns = ''\n",
    "    select = ''\n",
    "    \n",
    "    # create or find global data job \n",
    "    try:\n",
    "        global_dj = pool.data_jobs.find('Unify Tables')\n",
    "    except:\n",
    "        global_dj = pool.create_data_job(name = 'Unify Tables')\n",
    "    \n",
    "    #loop through defined tables\n",
    "    for table_name in tables:\n",
    "    \n",
    "        # find tables to unify\n",
    "        x = 0\n",
    "        for schema in global_dj.tables:\n",
    "            for table in schema:\n",
    "                x = x + 1\n",
    "                if table['schemaName'] not in schemalist:\n",
    "                    continue\n",
    "                if table['name'] == table_name:\n",
    "                    sameTables.append(table)\n",
    "        \n",
    "        if len(sameTables) == 0:\n",
    "            print('TABLE', table_name, 'CAN NOT BE UNIFIED! Not existing in source systems!')\n",
    "            global_dj.create_transformation(name = \"Unify \" + table_name, statement = '-- no existing tables to unify in defined source systems')\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # create minimal column requirement\n",
    "            for col in sameTables[0]['columns']:\n",
    "                try:\n",
    "                    if col in sameTables[1]['columns']:                                              # ERROR CHECKING !\n",
    "                        minReq.append(col)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            \"\"\"\n",
    "            #only required if function = 'min'\n",
    "\n",
    "            if len(sameTables) > 2:\n",
    "                for table in sameTables[2:]:\n",
    "                    for col in minReq:\n",
    "                        if col not in table['columns']:\n",
    "                            minReq.pop(col)\n",
    "                # create transformation statement for minimal table requirement\n",
    "\n",
    "            if function == 'min':\n",
    "                for col in minReq:\n",
    "                    if(minReq.index(col) == 0):\n",
    "                        columns += '{}\\n'.format(col['name'])\n",
    "                    else:\n",
    "                        columns += ',{}\\n'.format(col['name'])\n",
    "                for table in sameTables:\n",
    "                    select += 'SELECT \\n{}FROM \"{}\".\"{}\"'.format(columns, table['schemaName'], table_name)\n",
    "                    if table != sameTables[len(sameTables)-1]:\n",
    "                        select += '\\nUNION ALL\\n'\n",
    "            \"\"\"            \n",
    "\n",
    "            # create transformation for statement for extension with null\n",
    "            if function == 'null':\n",
    "                #columns = ''\n",
    "                #select = ''\n",
    "                \n",
    "                for table in sameTables:\n",
    "                    for col in table['columns']:\n",
    "                        if col not in maxReq:\n",
    "                            maxReq.append(col)\n",
    "                for table in sameTables:\n",
    "                    for col in maxReq:\n",
    "                        if(maxReq.index(col) == 0):\n",
    "                            columns += \"'\" + table['schemaName'] + \"' \" + 'AS \"SCHEMA\"\\n' + ',{}\\n'.format('\"' + col['name'] + '\"' if col in table['columns'] else 'NULL AS \"' + col['name'] + '\"')\n",
    "                        else:\n",
    "                            columns += ',{}\\n'.format('\"' + col['name'] + '\"' if col in table['columns'] else 'NULL AS \"' + col['name'] + '\"')\n",
    "                    select += 'SELECT \\n{}FROM \"{}\".\"{}\"'.format(columns, table['schemaName'], table_name)\n",
    "                    columns = ''\n",
    "                    if table != sameTables[len(sameTables)-1]:\n",
    "                        select += '\\nUNION ALL\\n'\n",
    "            # create transformation\n",
    "            #statement = 'DROP VIEW IF EXISTS \"{}_UNIFIED\";\\n\\nCreate VIEW \"{}_UNIFIED\" AS(\\n{}\\n);'.format(table_name, table_name, select)\n",
    "            statement = 'DROP VIEW IF EXISTS \"{}\";\\n\\nCreate VIEW \"{}\" AS(\\n{}\\n);'.format(table_name, table_name, select)                      ### <-- Unified\n",
    "            global_dj.create_transformation(name = \"Unify \" + table_name, statement = statement)\n",
    "            print('The union statement has been saved in the global data job \"Unify Tables\" for Table', table_name)\n",
    "            select = ''\n",
    "            sameTables = []\n",
    "            minReq = []\n",
    "            maxReq = []\n",
    "            \n",
    "            # reminder: datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-28 14:05:26 - pycelonis: Login successful! Hello josef.rieger@cbs-consulting.de\n",
      "2020-09-28 14:05:27 - pycelonis: Best matches: [(0.44, 'Transformation PP'), (0.41, 'PP2 005 - SAP ECC PP - Full Extraction'), (0.41, 'PP2 004 - SAP ECC PP - Full Extraction')]\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table AFKO\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table AFPO\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table AFRU\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table AUFK\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table AUFM\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table CDHDR\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table CDPOS\n",
      "TABLE CEPCT CAN NOT BE UNIFIED! Not existing in source systems!\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table CRHD\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table CRTX\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table DD02T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table DD03M\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table JCDS\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table JSTO\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LTAK\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table LTAP\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MAKT\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MARA\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MARC\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table MBEW\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T001\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T001K\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T001W\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T003O\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T003P\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T003T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T023T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T156T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table T399X\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCO43\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCORU\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURC\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURF\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURR\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCURX\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TCX00\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TGSBT\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TJ02T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table TJ30T\n",
      "The union statement has been saved in the global data job \"Unify Tables\" for Table USR02\n"
     ]
    }
   ],
   "source": [
    "# URL to the Cloud Data Pool where the tables to unify are hosted.\n",
    "url = 'https://endresshauser.eu-3.celonis.cloud/'\n",
    "\n",
    "# Specify a valid API token for your Cloud Team.\n",
    "#Click on Team Settings -> Edit -> create or copy already inserted API key\n",
    "\n",
    "api_token = 'N2JmNDI0NjMtNWQ3ZS00OGUzLTk3OTctYmJjMGM4OGE4Yjk2OnVtL3I0UldzVllJeTIwZFFIZ043R2FrTVUxRDEySFE5YWRHWnJtU2p6SkJL'\n",
    "\n",
    "\n",
    "#To get the data pool id, you have to run the following code. To get the data\n",
    "#the ML User here called Global needs permission to request these informations\n",
    "#celonis = get_celonis()\n",
    "#celonis.pools by that you get the ID for the data pool \n",
    "\n",
    "# Specify a datapool -- PP Data Pool ID\n",
    "datapool = '590652c7-87a4-46e6-a9e9-60c90cb7c4e3'\n",
    "\n",
    "# Specify the table names for which the tables should be merged. \n",
    "\n",
    "#CEPECT is empty in all systems\n",
    "tables = [\n",
    "'AFKO','AFPO','AFRU',\n",
    "'AUFK','AUFM','CDHDR','CDPOS','CRHD','CRTX','DD02T','DD03M','JCDS','JSTO','LTAK','LTAP','MAKT','MARA','MARC','MBEW','T001','T001K','T001W','T003O','T003P','T003T','T023T','T156T','T399X','TCO43','TCORU','TCURC','TCURF','TCURR','TCURX','TCX00','TGSBT','TJ02T','TJ30T','USR02', \n",
    "]\n",
    "\n",
    "\n",
    "# Specify 'min' if the unified table should be the minimal column requirement and 'null' if the not existing columns should be filled with null values.\n",
    "function = 'null'\n",
    "\n",
    "# Specify the required table schemas in a python list\n",
    "#To acess the Schema Name you have to get the connection informations\n",
    "#pool.data_connections\n",
    "tableSchema = [\n",
    "'590652c7-87a4-46e6-a9e9-60c90cb7c4e3_fff504b3-61e6-431a-9589-a0c8a1ccd3c6', # SAP ECC - PIN-020\n",
    "'590652c7-87a4-46e6-a9e9-60c90cb7c4e3_bd6565ee-257a-4349-b3a2-ad0dfa097db7', # SAP ECC - PIN-024\n",
    "'590652c7-87a4-46e6-a9e9-60c90cb7c4e3_9ea3d196-29ab-45e3-b825-4f6b80c543d2', # SAP ECC - PP1-011\n",
    "'590652c7-87a4-46e6-a9e9-60c90cb7c4e3_f9111368-fa6e-436c-b891-ad340f7d20d8', # SAP ECC - PP2-004\n",
    "'590652c7-87a4-46e6-a9e9-60c90cb7c4e3_897d99cb-b81d-4da1-b3da-d6c986f854bf' # SAP ECC - PP2-005\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "unify_tables(url = url, api_token = api_token, datapool = datapool, tables = tables, tableSchema = tableSchema, function = function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
